{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBdcIQ7nLzNj"
      },
      "source": [
        "# Assessment 2: Machine Learning and Optimisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMondJpmL3jg"
      },
      "source": [
        "## Part 1 - Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLc-NOz1L7Y6"
      },
      "source": [
        "### Task 1.1 - Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkUjx-nTMdt0"
      },
      "source": [
        "#### Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "V7FOfSRQL_gM"
      },
      "outputs": [],
      "source": [
        "## Imports\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.decomposition import PCA\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "## Used for normalising the data\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "## Used for regression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "## Used for assessment of regression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "## Used for cross validation\n",
        "import pandas \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score as CV\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsbY820IMwiI"
      },
      "source": [
        "#### Loading and preparing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "cCoxW9vZM3ti",
        "outputId": "920b65b1-d76c-4b31-d1a0-4b1c52b14c01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /sklearn-master\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-2fb1a21c1aec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/COMP2002_CW2/MyDrive/COMP2002_CW2/ENB2012_data.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    113\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m       \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m       ephemeral=True)\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server, ephemeral)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mnormed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnormed\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must be in a directory that exists'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m   \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_signal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIGKILL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Mountpoint must be in a directory that exists"
          ]
        }
      ],
      "source": [
        "## Loading dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/sklearn-master', force_remount=True)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/COMP2002_CW2/MyDrive/COMP2002_CW2/ENB2012_data.xlsx')\n",
        "\n",
        "from google.colab import drive+-\n",
        "drive.mount('/COMP2002_CW2')\n",
        "\n",
        "dataframe =  data.values[:,:-1].astype(float)\n",
        "classes = [\"X1\", \"X2\"]\n",
        "targets = [classes.index(cls_str) for cls_str in data.values[:,-1].astype(str)]\n",
        "targets = np.array(targets)\n",
        "\n",
        "\n",
        "# Scale the data.\n",
        "scaler = MinMaxScaler()\n",
        "scaled = scaler.fit_transform(dataframe)\n",
        "\n",
        "# Print the range of the variables to show the normalisation effect.\n",
        "print(dataframe.ptp(axis=0))\n",
        "print(scaled.ptp(axis=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UbBOF8YOjX4"
      },
      "source": [
        "### Task 1.2 - Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLxHfij9O5vX"
      },
      "source": [
        "#### Regression using the \"sklearn.neural_network.MLPRegressor\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6agXlDk9Oosv"
      },
      "outputs": [],
      "source": [
        "neural_Regressor = MLPRegressor(hidden_layer_sizes=(20,), max_iter=1000, warm_start=True, random_state = 1, verbose=True)\n",
        "neural_Regressor.fit(scaled, targets.reshape(-1,))\n",
        "neural_Outputs = neural_Regressor.predict(scaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOiJ2euGPDIi"
      },
      "source": [
        "#### Regression using the \"sklearn.ensemble.RandomForestRegressor\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZm0TaBiPI7f"
      },
      "outputs": [],
      "source": [
        "randomForest_Regressor = RandomForestRegressor(max_depth=2, warm_start=True, random_state = 1, verbose=True)\n",
        "randomForest_Regressor.fit(scaled, targets.ravel())\n",
        "rf_Outputs = randomForest_Regressor.predict(scaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBh3t_m8wzfg"
      },
      "source": [
        "#### Regression using the \"sklearn.svm.SVR\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-G-nLt7wzfp"
      },
      "outputs": [],
      "source": [
        "SVR_Regressor = SVR(kernel='rbf')\n",
        "SVR_Regressor.fit(scaled, targets.ravel())\n",
        "SVR_Outputs = SVR_Regressor.predict(scaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tbe8xA_Bg6rU"
      },
      "source": [
        "### Task 1.3 - Assessment of  Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi-E4EBig_Kh"
      },
      "source": [
        "#### MSE of all 3 regression methods then plot it on a box plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJI9SME-hE0Z"
      },
      "outputs": [],
      "source": [
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "targets.reshape(-1, 1)\n",
        "neural_Outputs.reshape(-1, 1)\n",
        "rf_Outputs.reshape(-1, 1)\n",
        "SVR_Outputs.reshape(-1, 1)\n",
        "MSE_1 = cross_val_score(neural_Regressor, targets, scaled, cv=5)\n",
        "print(MSE_1)\n",
        "\n",
        "MSE_2 = cross_val_score(randomForest_Regressor, targets, scaled, cv=5)\n",
        "print(MSE_2)\n",
        "\n",
        "MSE_3 = cross_val_score(SVR_Regressor, targets, scaled, cv=5)\n",
        "print(MSE_3)\n",
        "\n",
        "plot_data = list()\n",
        "plot_data.append(MSE_1)\n",
        "plot_data.append(MSE_2)\n",
        "plot_data.append(MSE_3)\n",
        "\n",
        "\n",
        "# Creating plot\n",
        "plt.boxplot(plot_data)\n",
        " \n",
        "# show plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0v-FZ-VgRDCa"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Assessment_2_Machine_Learning_and_Optimisation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}